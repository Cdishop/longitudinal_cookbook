---
output: pdf_document
---

# Discussion

There are many different patterns to explore with longitudinal data structures. This manuscript, by unpacking between-unit patterns, mirrors the common questions and inferences currently emphasized by organizational scientists. What is the between-unit relationship among a set of constructs (averaged over time)? What is the between-unit expected trend? Are there between-unit differences in trend (also phrased as, "between-unit differences in within-unit change")? We organized these questions and inferences into a fundamental set, discussed what they mean, and linked the inferences to appropriate statistical models. Ultimately, researchers should now be able to understand the spectrum of between-unit inferences that they can explore with rich, longitudinal data.  

Between-unit questions are common and useful and they are the sibling to an alternative lens to asking questions and making inferences with repeated measures: within-units. Within-unit inferences emphasize fluctuations over time rather than across units. For example, Beal [-@beal_esm_2015] notes that many of the psychological phenomenon in which we are interested are "sequences of events and event reactions that happen within each person's stream of experience" (p. 5). This is a within-unit statement: it emphasizes how a construct moves through time within a single individual. Organizational scientists have become increasingly interested in within-unit perspectives over the past decade. @dalal2014within review theory and research on within-person job performance, @grandey2015emotional review emotional labor and differentiate a variety of within-person perspectives, @park2013advancing present a team motivation model describing within-individual resource allocation and within-team feedback, @vancouver2010formal present a within-person model of multiple-goal pursuit, @barnes2012working describes recent within-person approaches to sleep and organizational behavior, and @methot2017good present a within-person perspective of organizational citizenship behaviors. There are many within-person inferences accumulating in our literature, but they are occasionally accompanied by between-person models or are dispersed and unconnected among different content areas. An immediate next step for future research is to create a framework for the fundamental within-unit inferences. 

Our focus was on between-unit patterns because these inferences are the backbone of longitudinal modeling in organizational science. Moreover, there can be a tendency for researchers to believe that they are making within-unit inferences simply because they collect longitudinal data, our goal was to build consensus and clarity on the fundamental between-unit ideas in longitudinal data structures. We close the paper by broadening our view slightly, we discuss two complexities that merit attention when researchers apply -- irrespective of the inferential lens that they take -- statistical models to longitudinal data.

When researchers explore patterns in longitudinal data, regardless of whether they emphasize between or within-unit inferences, there are additional statistical complexities to consider that influence the veracity of a researcher's conclusions. For example, consider a researcher interested in inference one from the "relationships" section of this paper. To explore it, she collects data on 400 subjects across eight time points, applies a recommended statistical model, and then evaluates the results and makes an inference about the underlying process. Although she aligned her question with an appropriate statistical model, there is an issue related to her data that she did not assess. The longitudinal data that she collected may not contain the statistical characteristics that merit her inference. She can ask questions about its patterns, apply a statistical model to it and make statements that are appropriate *given only the statistical model that she applied*, but we do not know if her inference is appropriate *given the statistical characteristics of the data that she applied her model to*. Do the data merit her inference in the first place?

The statistical complexities that we discuss below include stationarity and ergodicity. Stationarity and ergodicity are statistical characteristics that can be assessed with longitudinal data, and we discuss both below in the context of advocating for greater $T$, for researchers to collect more observations over time because statistical models alone do not reveal stationarity or ergodicity if the analyst is not meticulously looking for them. They require tests of their own and the tests are facilitated by data structures with more time points. 

Processes give rise to observed data and those observed data are characterized by distributions and their moments. Stationarity is about whether or not the statistical characteristics of a process remain stable over time. When they do, the analyst has permission to use a variety of regression-based techniques like those described in this paper without additional concerns of faulty inferences. When trajectories are non-stationary, however, then the inferences drawn from regression-based techniques are often misguided [@granger_spurious_1974]. Full explanations of stationarity are in @kuljanin_cautionary_2011, @braun_spurious_2013, @jebb2015time, and @metcalfe2009introductory, we draw attention to it here to emphasize that studies with greater $T$ have the ability to assess stationarity and understand which statistical models are appropriate. Moreover, finding evidence of (non)stationary is useful theoretical knowledge and needs to take the foreground of studies that collect longitudinal data.

Ergodicity is another statistical characteristic of a process and it is important because it determines whether or not researchers can generalize inferences of inter-individual variability from tests of between-unit differences to inferences of within-unit variability. To see the dilemma, consider the following. First, the standard statistical models in psychology and management, such as growth curves, multi-level models, mixture modeling, ANOVA, and factor analysis all focus on between-unit variation [@molenaar_manifesto_2004]. Second, researchers using these techniques run their computations on a sample drawn from a population and then generalize their results back to the population, so (a) the results live at the level of the population and (b) researchers assume that the population (or sub population in mixture modeling) is homogenous [@molenaar2009new]. These notions are fine on their own,  but often an additional assumption creeps in that is unlikely to hold: because resuls live at the level of the population and because researchers assume that the population is homogenous they often also assume that the results apply to the individuals making up the population [@molenaar2008implications]. In other words, they assume that the results from a test of between-unit variation hold at the level of within-individual variation.

When processes are ergodic, this implicit assumption holds: the results of an analysis of between-unit differences generalize to within-unit patterns and vice versa [@molenaar2007psychological; @molenaar2008consequences]. Researchers can generalize with ergodic processes, they can use a multi-level model to assess between-unit patterns and then make statements about within-person relationships. But this generalization is rarely appropriate. A Gaussian process is non-ergodic if it is non-stationarity (e.g., it has time-varying trends) and/or heterogeneous across subjects (subject-specific dynamics). Stated simply, a Gaussian process is non-ergodic if it has trend and/or Susie's trajectory is different from Bob's. If either is violated, which is often the case, then standard analyses of between-subject differences (growth models, multi-level or random-coefficient models, mixture models, ANOVA, factor analysis) cannot be used to make within-person statements. In general (but not always), within-person inferences need to come from unpooled, subject-specific time-series data structures [@molenaar2009generalization]. 

Stationarity and ergodicity are complex ideas that merit future discussion, the point here is that collecting large samples across many time points allows researchers to assess stationarity and ergodicity and explore both between and within-unit inferences. Often, though, researchers have finite resources that force them to decide whether to emphasize between or within-unit patterns. Your data collection should align with the inference that you are interested in. If you care about between-unit patterns (as shown in this paper), focus on $N$ -- collect data on many participants. If you care about within-unit patterns, focus on $T$ -- collect data across many time points. Large samples across many time points of course gives researchers the ability to explore both frameworks, but our field will need to recognize that a small samples (e.g., five or fewer participants) measured across many time points does allow a researcher to make within-person inferences (by definition) and is useful. Know your constraints and allocate your resources accordingly; gather lots of $N$ when your interest is between-unit and lots of $T$ when your interest is within-unit. 
