---
output: pdf_document
---

Take aways from last time:

* Change hook

    + An organizing paper on the inferences and models people make and use with longitudinal data. Not a "this is what true process is" paper. 
    
* Change structure

    + Open with Xu and DeShon figure to organize everything
    
    + Use generic variables throughout 
    
    + Data structures issues at end
    

Our literature contains many calls for studies to focus on how things happen over time. 
example
example
example

These calls have resulted in an increasing number of longitudinal studies. 


Although there are similarities across this literature, such as repeated meausures and phrases that end with "over time," anyone reading it would be confronted by many points of disconnect. Some researchers use hierarchical linear models (HLM), whereas others employ latent growth curves. Some make inferences about change, whereas others are interested in dynamics or growth. All of these authors are investigating patterns in longitudinal data, but it can be inclear how they fit together across the seemingly unrelated hypotheses, models, and inferences they make. 

Our goal is to organize. 
    

Interested in how things happen over time
- longer data sets
- discussions of models with longitudinal data
- various inferences
-but
-ambiguous and disconnected. hard to follow if you are new. we provide an organizing framework. 


Interested in inferences with longitudinal data.
- change, growth
- longer data sets
- diverse models


all empirical
-longer data sets
-models that can handle data over time
-inferences about things that happen over time


- longer data sets
-
- various inferences
-but
-ambiguous and disconnected. hard to follow if you are new. we provide an organizing framework.

# Hook 

The story I'm trying to tell:

* People want us to do stuff with longitudinal data, but this literature is messy and confusing. We could use some organization.

opening one
Interested in how things happen over time
greater emphasis in theory
greater number of time points among empirical studies
greater use of models that require longitudinal data

We --organizational researchers-- are increasingly interested in how things happen over time. Emergence, growth, change, dynamics, and process explanations are becoming explicit in organizational theory. Empirical tests of our theories now commonly collect longitudinal data sets with a growing number of time points. New statistical techniques to support inferences with these longitudinal data structures emerge every year. Computational modelers have made their role for refining process knowledge clear and their frequency appears to be growing. Across these developments, however, researchers present seemingly unrelated hypotheses and employ diverse statistical approaches – which impedes any unity about how to demonstrate and support a process inference.




opening two
there is now a large literature on inferences with longitudinal data.
greater number of longitudinal studies with growing number of time points
studies use models that require longitudinal data
make inferences about patterns that happen over time
write theory about what happens over time

opening three
we increasingly interested in how things happen over time. 
greater role in theory
explicit calls for research in this area

this results in empirical studies with a growing number of time points
models that require longitudinal data
inferences about the observed patterns in longitudianl data

but it is confusing. 


opening four
many calls for greater emphasis on how things happen over time

if a researcher was interested, they would then look to the literature on longitudinal investigations. They would find many. Greater use of longitudianl designs with a growing number of time points

although these studies have similarities, repeated measures and phrases that entail "over time," they use different models, make seeingly unrelated predictions and inferences, etc. etc. etc. What is a researcher to do?

we want to provide some clarity. 

# Hook

The story I am trying to tell:

* People want us to do stuff with longitudinal data, to make inferences over time. But this literature is messy and confusing. We could use some organization.

To satisfy these calls, we might want to conduct our own longitudinal investigation and look to the literature for help. 






Increasingly interested in how things happen over time
results in a literature where there are many similarities, such as their repeated measures and use of phrases with 'over time.' 

We – organizational researchers – are increasingly interested in how things happen over time. 
- empirical studies collect more time points
- greater use of models that require longitudinal data
- greater focus in theory
- greater number of inferences

When you look at this literature there are a number of similarities. 
-stuff about the increasing interest of how things happen over time




Empirical studies, for example, commonly employ longitudinal designs and collect data over a growing number of time points. Two decades ago the typical data structure was..., whereas today we (Or, the last five pubs in JOM & JAP were all longitudinal) ... Moreover, researchers appear to be placing greater emphasis on modeling techniques that can handle longitudinal data. It is now common to use hierarchical linear (or random-coefficient or multi-level) modeling to capture relationships over time, and a growing number of studies now use latent growth curve models (cites). Finally, researchers collect and apply models to these data to ultimately form inferences, such as change or growth, about the patterns they observe.



Among these developments, researchers present seemingly unrelated hypotheses, diverse statistical models, and tend to focus on one inference, or a set of inferences, related to one dimension at play in longitudinal data (e.g., growth). 

BUT IF YOU WERE TO LOOK AT THESE STUDIES YOU WOULD FIND UNRELATED INFERENCES. RELATIONSHIPS, CHANGE, GROWTH. THESE ARE ALL "OVER TIME," BUT IT IS UNCLEAR HOW THEY ARE ORGANIZED OR RELATED. 

interested in how things happen over time. 
-longitudinal data sets

Common
-models
-over time

Look at these studies, you find common areas -- repeated measures, descriptions that use the phrase "over time" -- but many areas that appear unrelated. Different inferences, different models, different hypotheses. 

either HLM or growth models -- but 





using models there appears to be a greater use of staistical models 

researchers using modeling strategies to handle longitudinal data. 

Researchers then apply These data structures then draw greater use of statistical models that are amenable to longitudinal designs. Hiarchical linear modeling (or random-coefficient, multi-level) 

Moreover, we also see greater use of statistical models  researchers apply models that can handle longitudinal data

our statistical literature appears to take interest in emphasizes shows a greater emphasis on 

statistical literature on the models that can be applied to these data sets. 

new models and statistical techniques to apply to these data emerge every year. Some examples include ... Finally, there are a variety of inferences researchers make about the relationships they observe with longitudinal data, inferences 

Empirical studies commonly employ longitudinal designs and collect data over a growing number of time points, new models and statistical techniques to apply to these data emerge every year, and there are a variety of inferences researchers make about the relationships they observe with longitudinald data. 

Emergence, growth, change, dynamics, and process explanations are becoming explicit in organizational theory. Empirical tests of our theories now commonly collect longitudinal data sets with a growing number of time points. New statistical models  and  New statistical techniques to support inferences with these longitudinal data structures emerge every year. Computational modelers have made their role for refining process knowledge clear and their frequency appears to be growing. Across these developments, however, researchers present seemingly unrelated hypotheses and employ diverse statistical approaches – which impedes any unity about how to demonstrate and support a process inference.

Researchers that study process are therefore in a similar state to those that were interested in multilevel phenomena two decades ago. Then, we debated how to measure multilevel constructs, justify aggregation, and analyze multilevel models (Klein & Kozlowski, 2000), and our research advanced only after developing consensus. Now, we conceptualize and model different aspects of process -- such as change, growth, or dynamics -- without a shared understanding of the diverse approaches and pitfalls of each. We need to clearly understand how researchers’ approach and justify the variety of inferences they make about the processes in longitudinal data – and the drawbacks of each – to avoid inferential errors and to develop the process knowledge so many authors call for (zillion cites). 

Our goal is to explain these various approaches and provide a guide for researchers who want to study process. Researchers tend to focus on an inference, or set of inferences, related to one dimension at play in longitudinal data (e.g., growth), and this results in seemingly unrelated hypotheses and model applications across research streams. We unpack the core inference underlying each, discuss their differences, provide examples and direct readers to possible statistical models, and show how they can be used to cumulatively understand process.

# Intro

Hype process. Introduce inferences.



![](figures/common_models.png)

# Relationships 

## Inference 1

The relationship of one or more predictor variables with a response variable over time.

### Examples

#### Hypotheses 

@barnes2011 and @chi2015 present hypotheses that are consistent with a relationships inference. @barnes2011 predict a negative relationship between poor sleep and cognitive self control. Similarly, @chi2015 hypothesize that daily negative mood negatively relates to daily task performance. 

#### Longitudinal Data Structure 

Researchers that infer relationships over time either a) measure their variables at the same time points or b) treat the data as if they were measured as so by the constraints of their analysis. @barnes2011 give an example of the former; they measure sleep and cognitive self control every morning for five consecutive days (study 4). @chi2015, as an example of the latter, measure negative mood in the morning and task performance in the afternoon -- but these variables are treated as if they were taken at the same time (e.g., day 4) when entered into their analysis (described later).

There is no limit to the number of possible time points, but studies of this type typically collect between three and ten repeated measurements. Our examples above measure their variables once per day, but other frequencies could also be used. Methods literature typically recommends that researchers maintain the same interval between each measurement across their study, but this can be difficult when studies last longer than a week. For example, @chi2015 take their measurements for ten work days. In the middle of those assessments, however, their sample employees go home for the weekend and are not measured. The space, therefore, between $t$ and $t + 1$ is not the same across their analysis. Finally, our organizational literature almost always takes measures on more than one unit across time.

#### Models 

Both @barnes2011 and @chi2015 use hiearchical linear modeling (HLM) -- also known as multi-level or random coefficient models -- to estimate the parameters that generate their observed data. Random coefficient models assume that their random effects are distributed $N(\gamma, \sigma^2)$ -- but this statement is easier to understand with a contrast. Imagine that everyone in the sample receives their own $X_t$ on $Y_t$ effect and we then summarize those effects by taking their average. HLM, conversely, estimates one $X_t$ on $Y_t$ effect across units (people) but does so by imposing a normality constraint. Finally, @barnes2011 and @chi2015 use models that fall into the broader time-varying analysis class because their measurements of $X$ are allowed to vary over time. In time-invariant analyses, conversely, values of the covariate remain stable (e.g., gender). 

### Pitfalls and Recommendations

What can go wrong. Recommendation. Why.

# Growth

## Inference 1

What is the level of a construct at a given point in time?

### Examples

#### Hypotheses 

There are few (if any) studies that make direct predictions about construct levels at certain time points. Almost every longitudinal study, however, estimates an intercept term to approximate the answer. These terms are then discussed in the context of broader growth inferences that we discuss below. 

#### Longitudinal Data Structure 

This inference requires several repeated measures on one variable. For example, @zhu2016 measure work adjustment once a month for nine months (among expatriates) and @jones2016 measure concealing behaviors (among pregnant women) every week -- but it is not clear for how long they do so.

#### Models 

@zhu2016 use HLM to estimate their parmaters, whereas @jones2016 do so in a structural equation modeling framework. As stated, researchers are interested in an intercept estimate for this inference, and although they can place it on any time point, researchers typically use their first observation. In SEM, the intercept is a latent variable regressed on either an observed indicator (again, usually the first observation) or its latent equivalent. @jones2016, for example, regress their latent concealing behaviors intercept term on the latent variable for concealing behaviors at time one. In HLM, the investigator first creates a variable that represents time and then regresses the outcome on this time indicator to estimate an intercept term. For example, @zhu2016 regress work adjustment on time using HLM to estimate its initial level. 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 2

What are the patterns of a trajectory or trajectories across time? How does the construct change over time?

### Examples

#### Hypotheses 

@zhu2016 predict that expatriate work adjustment follows a positive trajectory, increasing over the time of the assignment. Similarly, @jones2016 hypothesize that concealing behaviors will have negative slopes over time.

#### Longitudinal Data Structure

As with our previous inference, the only requirement here is a repeated assessment on one variable over several time points -- both @zhu2016 and @jones2016 meet these requirements.

#### Models

Researchers use slope terms in their models for making inferences about trajectory patterns. In HLM, the same procedure we described above -- regressing the outcome on time -- also provides a slope estimate. Typically researchers do not allow their slope estimates to vary over units, but the models can easily support random slope terms. @zhu2016, for example, estimate a random slope effect by regressing work adjustment on time. In SEM, a latent slope term is regressed onto all time points except for the time point that was used by the latent intercept term. @jones2016 regress a latent concealing behaviors slope term on latent concealing behaviors at all time points beyond $t_1$. 

Researchers may also be interested in curvilinear slopes. The only additional requirement for doing so is to create other time indicators with respect to the higher order polynomial. @zhu2016, for example, included linear, quadratic, and cubic time variables to estimate different slope curves. Note that these are still "linear" processes because they are linear in parameters. 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 3

Are there between person differences in trajectories or levels?

### Examples

#### Hypotheses 

Similar to our first growth inference, researchers rarely make a direct prediction about between person differences in trajectory or level, but it is almost always included as part of a larger growth analysis.

#### Longitudinal Data Structure

We now require repeated observations on multiple units to examine between person (unit) differences. For example, @zhu2016 collect data from 179 expatriates across nine consecutive months.

#### Models

Models that estimate intercept or slope terms also estimate a variance on those terms, and these are then subjected to significance tests. When the variance on the intercept is significant, that is taken to mean that there are between unit differences in intercept (levels), whereas significant variance estimates on the slope terms indicates between unit differences in slope (trajectory). @zhu2016 use HLM to estimate the variance on their intercept and slope terms and find evidence of between person differences in work adjustment intercept (level) and slope (trajectory). 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 4

How is the level of a construct related to the trajectory of the same or different constructs? What is the correlation between intercept and slope terms?

### Examples

#### Hypotheses

@schaubroeck2016 predict that initial levels of peer leader's transformational leadership will positively relate to the slope of employee beliefs. @zhu2016 hypothesize that initial level of expatriate work adjustment is negatively related to the speed of change in work adjustment. Notice that the first prediction is about how the level of one construct is related to the slope of another, whereas the second focuses only on a single variable. Although it is uncommon in our literature, developmental researchers will also predict associations between slope and the final -- rather than initial -- observation. 

#### Longitudinal Data Structure

Data structures that researchers use to examine this inference are consistent with what we have already reviewed. @schaubroeck2016 measured transformational leadership and employee beliefs at three time points. Their time two assessment was 10 weeks after their first observation, whereas their final measurement was taken 10 months after their second observation. That is, the data structure for their respective time points were $t$, $t + 10$, and $t + 40$. As stated above, @zhu2016 collected data once a month for nine months.

#### Models

Both HLM and SEM provide estimates of the covariance between the intercept and slope terms discussed above, and this covariance indicates the association between level and trajectory. For example, @zhu2016 report a negative covariance estimate betwen the initial level of expatriate work adjustment (intercept) and its linear trajectory over time (slope). As stated, researchers can also examine this association but among the level of one variable and the trajectory of a different variable. @schaubroeck2016 report an estimate of the relationship between transformational leadership intercept and employee beliefs slope. It is often helpful to generate predicted values using the analysis estimates and then plot the levels and trajectories to interpret them appropriately.

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 5

What inter-individual characteristics relate to intra-individual differences in level or slope?

### Examples

#### Hypotheses

Inferences of this type take the form of stable unit effects and their relationship with trajectory or level. @li2017 predict a positive relationship between job strain and job complexity trajectory. @zhu2016 hypothesize that the trajectory of expatriate work adjustment is positively related to perceived career instrumentality. Finally, @jones2016 make two inferences of this type: contextual support is a) negatively related to average levels of concealing but b) positively related to the slope of concealing.

#### Longitudinal Data Structures

We discussed the data structures for @zhu2016 and @jones2016 above. @li2017 use a similar design but their data are collected once per year. Job complexity is measured once every year for three years, and job strain is measured once at the final time point (year 3). 

#### Models

Both @li2017 and @zhu2016 use HLM to estimate their parameters, whereas @jones2016 do so with SEM. In these models, the intercept or slope terms discussed above are regressed onto the inter-individual characteristic. For example, @li2017 report the estimate of job strain predicting job complexity trajectory and @zhu2016 do the same but for career instrumentality and job complexity trajectory. In the SEM framework, @jones2016 report estimates of contextual support predicting concealing slope and intercept. Note that these models fit into the broader time-invariant analysis class that contrast with the time-variant covariates analyses discussed earlier. 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

# Change

## Inference 1

How are the changes of one variable associated with changes in another over time?

### Examples

#### Hypotheses

Change inferences are similar to relationship inferences in that they relate a predictor to a response at the same time point, but the researcher now wants to know whether the predictor is associated with an increase or decrease of the outcome. For example, @johnson2014 predict that, within individuals, exhibiting daily procedural justice behavior is associated with an increase in resource depletion. Similarly, @Lanaj2016 hypothesize that, within individuals, transformational leadership is associated with a decrease in negative affect. 

#### Longitudinal Data Structures

@johnson2014 measured justice behavior and resource depletion in the afternoon of 10 consecutive workdays. @Lanaj2016 measured their variables at different frequencies. They measured transformational leadership and negative affect in the afternoon of 15 consecutive workdays, but they also took an additional measurement of negative affect every morning -- creating a data structure of three variables: negative affect from $t$ to $t + 15$, transformational leadership from $t$ to $t + 15$ and morning negative affect from $t$ to $t + 15$. That is, they essentially doubled the time points of negative affect -- from $t$ to $t + 30$ by measuring it twice as frequently.


#### Models

@johnson2014 and @Lanaj2016 employ HLM change models that are consistent with our literature's preference for using partialed values of the outcome variable rather than difference scores. In models of this type, researchers regress their outcome on the predictor at the same time point and the prior value of the outcome variable. For example, @johnson2014 regressed resource depletion at time $t$ on 1) procedural justice behavior at time $t$ and 2) resource depletion at time $t-1$; they then report the relationship between justice behavior and resource depletion change. Similarly, @Lanaj2016 regress negative affect at time $t$ on 1) transformational leadership at time $t$ and 2) negative affect at time $t-1$ (i.e., morning negative affect) and report the association between transformational leadership and affect change. Note that, due to the different data sampling strategies, @johnson2014 reports change from the prior day, whereas @Lanaj2016 report change from the morning to afternoon. 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

# Dynamics

The core concept is: how are prior states related to future states?

## Inference 1

How is one variable related to its future self?

### Examples

#### Hypotheses

#### Longitudinal Data Structures

#### Models

### Pitfalls and Recommendations

## Inference 2

How is one variable related to a different variable in the future?

### Examples

#### Hypotheses

@gabriel2014 hypothesize that perceived P-O fit is positively related to subsequent positive affect. 

#### Longitudinal Data Structure

@gabriel2014 measured perceived P-O fit and positive affect five times per day for 10 consecutive work days.

#### Models

Researchers that use models related to this inference regress their outcome at time $t$ on a prior value of the independent variable. @gabriel2014 do so using HLM and regress perceive P-O fit at time $t$ on 1) positive affect at time $t-1$ and 2) perceived P-O fit at time $t-1$.

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 3

Directionality -- what is the relationship direction among a set of variables?

### Examples

#### Hypotheses

A directionality inference is typically explored using a pair of dynamic hypotheses. For example, @hardy2018 predict that 1) prior self efficacy negatively relates to subsequent meta cognition and 2) prior meta cognition positively relates to subsequent self efficacy. Similarly, @matthews2014 contrast two theories, one that predicts that work-family conflict is negatively related to subsequent well-being, whereas the other predicts that well-being is negatively related to work-family conflict.

#### Longitudinal Data Structures

@hardy2018 measured self efficacy and meta cognition after five evenly spaced computer game trails -- although they also measured baseline self efficacy. @matthews2014 assessed work-family conflict and well-being concurrently at three points in time: $t$, $t+1$, and $t+7$ where the intervals are months -- meaning that the final survey was assessed six months after the survey before it. 

#### Models

Both @hardy2018 and @matthews2014 use an SEM approach to estimate their parameters, but @matthews2014 restrict their model to a path analysis. Their modeling strategies are the same as those just presented, but they examine them as a set to explore the relationship direction among their variables. @matthews2014 find significant effects in both directions -- WFC predicting subsequent well-being and well-being predicting subsequent WFC -- and therefore suggest that the relationship works in both directions. @hardy2018 also report the estimates of self efficacy predicting subsequent meta cognition and vice versa, but only find significant effects for the latter. They conclude that "self-regulatory processes (i.e., exploration and meta cognition) positively influenced subsequent self-efficacy...In contrast, we only found limited support for the notion that self-efficacy significantly influences subsequent self-regulated learning processes" (p. 24). 

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 4

Reciprocal -- Is the pattern of relationships reciprocal, such that one variable influences another, and this latter variable then goes back to influence the first?

### Examples

#### Hypotheses

@kaltiainen2017 present a set of hypotheses to explore reciprocal dynamics among justice perceptions and trust. They predict that "process justice perceptions and cognitive trust have positive reciprocal relations over time. Specifically, planning stage (time 1) process justice (cognitive trust) perceptions will have a positive relationship with subsequent post-merger (time 2) cognitive trust (process justice) perceptions, which in turn will have a positive relationship with later post-merger (time 3) process justice (cognitive trust) perceptions" (p. idk). 

#### Longitudinal Data Structure

They assess cognitive trust and justice perceptions once a year for three years.

#### Models

@kaltiainen2017 evaluate a number of models but find best fit for a model that includes reciprocal relationships among justice and trust. In that model, trust at time $t$ is regressed on trust at time $t-1$ and justice at time $t-1$, and justice at time $t$ is regressed on trust at time $t-1$ and justice at time $t-1$. They find significant cross-lag effects for trust on justice at all times but only one significant cross-lag effect of justice on trust, and ultimately conclude that "the justice ${\Rightarrow}$ trust ${\Rightarrow}$ justice reciprocal relationship was supported but the trust ${\Rightarrow}$ justice ${\Rightarrow}$ trust relationship was not supported as the relationship between justice at time 2 and cognitive trust at time 3 was not statistically significant" (p. 14).

### Pitfalls and Recommendations

What can go wrong. Recommendations. Why.

## Inference 5

Mediation -- one variable influences an outcome through an intermediate variable


# Things to notice and questions

1) Not going example by example, I am combining them.

    * Originally I thought it would be more clear this way, but I could be wrong. I do not have enough examples to pair every inference with its own unique empirical example. 
    

2) Pitfalls and recommendations after each inference (as I did here...) or after each entire inference section (i.e., one for relationships, one for growth, etc.)?


3) "We" or "they" phrasing?

    * I.e., "we as a field typically do this..." or "researchers tend to do this..."
    
    * Not for stylistic reasons but for authoritative reasons.
    

4) Several issues that came up while writing the data structures sections

    * 1) They are repetitive
    
    * 2) Each example has their own issue (e.g., spacing between t and t + 1 isn't consistent, or the variables were measured at different frequencies). If I bring them up out of the blue it is really easy to lose the reader.
    
    * Solutions
    
        + I could write one data structure piece per inference section rather than one per inference
        
        + I could skip data structures in the inference examples -- just provide hypotheses and models -- and then give them their own section later
        
        + I could give pictures like figure 1 in Xu and DeShon in each inference example section and then give data structures and issues their own section later. That is, in the examples I simply speak about hypotheses and models as if every study measured their variables from $t$ to $t + 10$ on the same interval. Then, at the end I come back with data collection problems/discrepancies I noticed in the articles. I like this option. 






